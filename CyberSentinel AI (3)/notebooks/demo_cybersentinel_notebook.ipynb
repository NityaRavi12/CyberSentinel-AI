{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238b08ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"üöÄ CyberSentinel AI Demo - Starting...\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4949c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add parent directory to path to import CyberSentinel modules\n",
    "current_dir = os.path.dirname(os.path.abspath('.'))\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "print(f\"üìÅ Current directory: {current_dir}\")\n",
    "print(f\"üìÅ Parent directory: {parent_dir}\")\n",
    "print(f\"üìÅ Python path includes: {parent_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03502513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test basic imports\n",
    "print(\"üî¥ DEMO 1: Testing Core Imports\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Test config\n",
    "try:\n",
    "    from core.config import settings\n",
    "    print(\"‚úÖ Config module imported successfully\")\n",
    "    print(f\"   Model path: {settings.model_path}\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Config import error: {e}\")\n",
    "\n",
    "# Test logging\n",
    "try:\n",
    "    from core.logging import get_logger\n",
    "    logger = get_logger(\"demo\")\n",
    "    print(\"‚úÖ Logging module imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Logging import error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fe9e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test ML models\n",
    "print(\"\\nüî¥ DEMO 2: ML Model Testing\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "    from core.ml_models import threat_classifier, severity_assessor, anomaly_detector, nlp_model\n",
    "    print(\"‚úÖ ML models imported successfully\")\n",
    "    \n",
    "    # Test threat classification\n",
    "    test_texts = [\n",
    "        \"Suspicious email with malicious attachment detected\",\n",
    "        \"User clicked on phishing link in email\",\n",
    "        \"Ransomware detected on workstation\",\n",
    "        \"DDoS attack against web server\"\n",
    "    ]\n",
    "    \n",
    "    print(\"üéØ Threat Classification Results:\")\n",
    "    for text in test_texts:\n",
    "        threat_type, confidence = threat_classifier.predict(text)\n",
    "        print(f\"   '{text[:50]}...' -> {threat_type} ({confidence:.2f})\")\n",
    "    \n",
    "    # Test severity assessment\n",
    "    print(\"\\n‚ö†Ô∏è Severity Assessment Results:\")\n",
    "    test_features = [\n",
    "        {\"description\": \"Critical system breach detected\", \"confidence\": 0.9},\n",
    "        {\"description\": \"Minor suspicious activity\", \"confidence\": 0.3},\n",
    "        {\"description\": \"Urgent: Ransomware spreading\", \"confidence\": 0.95}\n",
    "    ]\n",
    "    \n",
    "    for features in test_features:\n",
    "        severity, confidence = severity_assessor.predict(features)\n",
    "        print(f\"   '{features['description']}' -> {severity} ({confidence:.2f})\")\n",
    "    \n",
    "    # Test NLP analysis\n",
    "    print(\"\\nüìù NLP Analysis Results:\")\n",
    "    test_text = \"URGENT: Critical security breach detected. Multiple systems compromised.\"\n",
    "    sentiment = nlp_model.analyze_sentiment(test_text)\n",
    "    entities = nlp_model.extract_entities(test_text)\n",
    "    \n",
    "    print(f\"   Sentiment: {sentiment['sentiment']} ({sentiment['confidence']:.2f})\")\n",
    "    print(f\"   Entities found: {len(entities)}\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå ML models import error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e474c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test monitoring\n",
    "print(\"\\nüî¥ DEMO 3: Monitoring System\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "    from core.monitoring import metrics_collector, health_checker\n",
    "    print(\"‚úÖ Monitoring modules imported successfully\")\n",
    "    \n",
    "    # Get current metrics\n",
    "    metrics = metrics_collector.get_current_metrics()\n",
    "    \n",
    "    print(\"üìà System Performance:\")\n",
    "    system_metrics = metrics.get('system', {})\n",
    "    print(f\"   CPU Usage: {system_metrics.get('cpu_percent', 0):.1f}%\")\n",
    "    print(f\"   Memory Usage: {system_metrics.get('memory_percent', 0):.1f}%\")\n",
    "    print(f\"   Uptime: {system_metrics.get('uptime', 0):.1f} seconds\")\n",
    "    \n",
    "    print(\"\\nüéØ Threat Processing:\")\n",
    "    threat_metrics = metrics.get('threats', {})\n",
    "    print(f\"   Total Threats: {threat_metrics.get('total_threats', 0)}\")\n",
    "    print(f\"   Auto Resolution Rate: {threat_metrics.get('auto_resolution_rate', 0):.1%}\")\n",
    "    print(f\"   Escalation Rate: {threat_metrics.get('escalation_rate', 0):.1%}\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Monitoring import error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bc577a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test LLM integration (optional)\n",
    "print(\"\\nüî¥ DEMO 4: LLM Integration\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "    from core.llm_agent import llm_agent\n",
    "    print(\"‚úÖ LLM agent imported successfully\")\n",
    "    \n",
    "    # Check if LLM clients are available\n",
    "    if llm_agent.openai_client or llm_agent.anthropic_client:\n",
    "        print(\"‚úÖ LLM clients available\")\n",
    "        print(\"   Note: Full LLM demo requires API keys\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è LLM clients not configured (API keys needed)\")\n",
    "        print(\"   To enable LLM features, set OPENAI_API_KEY or ANTHROPIC_API_KEY\")\n",
    "        \n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå LLM agent import error: {e}\")\n",
    "    print(\"This is optional - LLM features require API keys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2105311d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test security features\n",
    "print(\"\\nüî¥ DEMO 5: Security Features\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "    from core.security import auth_service, validate_input, validate_threat_data\n",
    "    print(\"‚úÖ Security modules imported successfully\")\n",
    "    \n",
    "    # Test input validation\n",
    "    print(\"üõ°Ô∏è Input Validation Test:\")\n",
    "    test_input = \"<script>alert('xss')</script>\"\n",
    "    sanitized = validate_input(test_input)\n",
    "    print(f\"   Original: {test_input}\")\n",
    "    print(f\"   Sanitized: {sanitized}\")\n",
    "    \n",
    "    # Test user authentication\n",
    "    print(\"\\nüîê Authentication Test:\")\n",
    "    try:\n",
    "        user = auth_service.authenticate_user(\"admin\", \"Admin123!\")\n",
    "        if user:\n",
    "            print(f\"   ‚úÖ Admin user authenticated successfully\")\n",
    "            print(f\"   Roles: {user.roles}\")\n",
    "        else:\n",
    "            print(\"   ‚ùå Authentication failed\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ö†Ô∏è Authentication test skipped: {e}\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Security import error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7083d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test API server\n",
    "print(\"\\nüî¥ DEMO 6: API Server\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "    from api.server import app\n",
    "    print(\"‚úÖ API server imported successfully\")\n",
    "    print(\"   Server ready to start with: uvicorn api.server:app --reload\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå API server import error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8aea85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample data visualization\n",
    "print(\"\\nüî¥ DEMO 7: Data Visualization\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Sample threat data for visualization\n",
    "threat_types = ['Malware', 'Phishing', 'Ransomware', 'DDoS', 'Unknown']\n",
    "threat_counts = [45, 30, 15, 10, 5]\n",
    "severity_levels = ['Low', 'Medium', 'High', 'Critical']\n",
    "severity_counts = [20, 40, 30, 10]\n",
    "\n",
    "# Create visualizations\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Threat types distribution\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.pie(threat_counts, labels=threat_types, autopct='%1.1f%%', startangle=90)\n",
    "plt.title('Threat Types Distribution')\n",
    "\n",
    "# Severity levels\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.bar(severity_levels, severity_counts, color=['green', 'yellow', 'orange', 'red'])\n",
    "plt.title('Threat Severity Distribution')\n",
    "plt.ylabel('Number of Threats')\n",
    "\n",
    "# Processing time over time (simulated)\n",
    "plt.subplot(1, 3, 3)\n",
    "time_points = range(1, 11)\n",
    "processing_times = [2.1, 1.8, 2.3, 1.9, 2.0, 1.7, 2.2, 1.6, 1.9, 2.1]\n",
    "plt.plot(time_points, processing_times, marker='o')\n",
    "plt.title('Processing Time Trend')\n",
    "plt.xlabel('Time Period')\n",
    "plt.ylabel('Processing Time (seconds)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f17d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo complete\n",
    "print(\"\\nüéâ DEMO COMPLETE!\")\n",
    "print(\"=\" * 60)\n",
    "print(\"‚úÖ All core features tested successfully\")\n",
    "print(\"‚úÖ ML models operational\")\n",
    "print(\"‚úÖ Security features active\")\n",
    "print(\"‚úÖ Monitoring system functional\")\n",
    "\n",
    "print(\"\\nüöÄ Next Steps:\")\n",
    "print(\"   1. Run the main application: python main.py\")\n",
    "print(\"   2. Test the API: python test_api.py\")\n",
    "print(\"   3. Run the LLM demo: python scripts/demo_llm.py\")\n",
    "print(\"   4. Check the README.md for full documentation\")\n",
    "\n",
    "print(\"\\nüîó Useful Resources:\")\n",
    "print(\"   - API Documentation: http://localhost:8000/docs\")\n",
    "print(\"   - Health Check: http://localhost:8000/health\")\n",
    "print(\"   - Metrics Dashboard: http://localhost:8000/metrics\")\n",
    "\n",
    "print(\"\\nüìä System Status:\")\n",
    "print(\"   - Core modules: ‚úÖ Working\")\n",
    "print(\"   - ML models: ‚úÖ Operational\")\n",
    "print(\"   - Security: ‚úÖ Active\")\n",
    "print(\"   - Monitoring: ‚úÖ Functional\")\n",
    "print(\"   - LLM integration: ‚ö†Ô∏è Requires API keys\") "
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
